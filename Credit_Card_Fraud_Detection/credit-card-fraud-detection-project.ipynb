{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform exploratory  Data Analysis and determine Training Labels\n",
    "\n",
    "*   Create a column for the class\n",
    "*   Standardize the data\n",
    "*   Split into training data and test data\n",
    "\n",
    "\\-Find best Hyperparameter for **Logistic Regression**, **Decision Trees**, **K-Nearest-neighbours (KNN)**, **Support Vector Machine (SVM)**, **Random Forest**, and \n",
    "\n",
    "*   Find the method performs best using test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Define Auxiliary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will import the following libraries for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:36:12.082592Z",
     "iopub.status.busy": "2021-11-27T02:36:12.081627Z",
     "iopub.status.idle": "2021-11-27T02:36:13.539373Z",
     "shell.execute_reply": "2021-11-27T02:36:13.538233Z",
     "shell.execute_reply.started": "2021-11-27T02:36:12.082526Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pandas is a software library written for the Python programming language for data manipulation and analysis.\n",
    "import pandas as pd\n",
    "# NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
    "import numpy as np\n",
    "# Matplotlib is a plotting library for python and pyplot gives us a MatLab like plotting framework. We will use this in our plotter function to plot data.\n",
    "import matplotlib.pyplot as plt\n",
    "#Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics\n",
    "import seaborn as sns\n",
    "# Preprocessing allows us to standarsize our data\n",
    "from sklearn import preprocessing\n",
    "# Allows us to split our data into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Allows us to test parameters of classification algorithms and find the best one\n",
    "#from sklearn.model_selection import GridSearchCV  ## We did not use\n",
    "# Allows us to test accuracy by jaccard_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "# Allows us to see the confusion matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Allows us to see the classification_report or F1 Score\n",
    "from sklearn.metrics import classification_report\n",
    "# Allows us to see the log loss score\n",
    "from sklearn.metrics import log_loss\n",
    "# Logistic Regression classification algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Support Vector Machine classification algorithm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "# Decision Tree classification algorithm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# K Nearest Neighbors classification algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Import Library for Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:36:22.954509Z",
     "iopub.status.busy": "2021-11-27T02:36:22.953951Z",
     "iopub.status.idle": "2021-11-27T02:36:25.417784Z",
     "shell.execute_reply": "2021-11-27T02:36:25.416736Z",
     "shell.execute_reply.started": "2021-11-27T02:36:22.954457Z"
    }
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"/Users/ashraful/Dropbox/deep_learning_project/creditcard_fraud_detection/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape of the data, head and tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:36:34.139134Z",
     "iopub.status.busy": "2021-11-27T02:36:34.138112Z",
     "iopub.status.idle": "2021-11-27T02:36:34.175383Z",
     "shell.execute_reply": "2021-11-27T02:36:34.174266Z",
     "shell.execute_reply.started": "2021-11-27T02:36:34.139083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. DATA SHAPE:  (284807, 31)\n",
      "2. DATA HEAD: \n",
      "    Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "3. DATA TAIL: \n",
      "             Time         V1         V2        V3        V4        V5  \\\n",
      "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
      "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
      "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
      "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
      "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
      "\n",
      "              V6        V7        V8        V9  ...       V21       V22  \\\n",
      "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
      "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
      "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
      "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
      "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
      "\n",
      "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
      "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
      "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
      "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
      "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
      "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
      "\n",
      "        Class  \n",
      "284802      0  \n",
      "284803      0  \n",
      "284804      0  \n",
      "284805      0  \n",
      "284806      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print('1. DATA SHAPE: ', data.shape)\n",
    "print('2. DATA HEAD: '\"\\n\",  data.head(5))\n",
    "print('3. DATA TAIL: '\"\\n\",  data.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the types of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:36:41.083245Z",
     "iopub.status.busy": "2021-11-27T02:36:41.082979Z",
     "iopub.status.idle": "2021-11-27T02:36:41.127137Z",
     "shell.execute_reply": "2021-11-27T02:36:41.126201Z",
     "shell.execute_reply.started": "2021-11-27T02:36:41.083217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:36:47.998890Z",
     "iopub.status.busy": "2021-11-27T02:36:47.998385Z",
     "iopub.status.idle": "2021-11-27T02:36:48.027435Z",
     "shell.execute_reply": "2021-11-27T02:36:48.026376Z",
     "shell.execute_reply.started": "2021-11-27T02:36:47.998838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe the summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:36:51.712012Z",
     "iopub.status.busy": "2021-11-27T02:36:51.711734Z",
     "iopub.status.idle": "2021-11-27T02:36:52.144143Z",
     "shell.execute_reply": "2021-11-27T02:36:52.143185Z",
     "shell.execute_reply.started": "2021-11-27T02:36:51.711982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.00</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>2.85e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.86</td>\n",
       "      <td>3.92e-15</td>\n",
       "      <td>5.68e-16</td>\n",
       "      <td>-8.76e-15</td>\n",
       "      <td>2.81e-15</td>\n",
       "      <td>-1.55e-15</td>\n",
       "      <td>2.04e-15</td>\n",
       "      <td>-1.70e-15</td>\n",
       "      <td>-1.89e-16</td>\n",
       "      <td>-3.15e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47e-16</td>\n",
       "      <td>8.04e-16</td>\n",
       "      <td>5.28e-16</td>\n",
       "      <td>4.46e-15</td>\n",
       "      <td>1.43e-15</td>\n",
       "      <td>1.70e-15</td>\n",
       "      <td>-3.66e-16</td>\n",
       "      <td>-1.22e-16</td>\n",
       "      <td>88.35</td>\n",
       "      <td>1.73e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.15</td>\n",
       "      <td>1.96e+00</td>\n",
       "      <td>1.65e+00</td>\n",
       "      <td>1.52e+00</td>\n",
       "      <td>1.42e+00</td>\n",
       "      <td>1.38e+00</td>\n",
       "      <td>1.33e+00</td>\n",
       "      <td>1.24e+00</td>\n",
       "      <td>1.19e+00</td>\n",
       "      <td>1.10e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.35e-01</td>\n",
       "      <td>7.26e-01</td>\n",
       "      <td>6.24e-01</td>\n",
       "      <td>6.06e-01</td>\n",
       "      <td>5.21e-01</td>\n",
       "      <td>4.82e-01</td>\n",
       "      <td>4.04e-01</td>\n",
       "      <td>3.30e-01</td>\n",
       "      <td>250.12</td>\n",
       "      <td>4.15e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-5.64e+01</td>\n",
       "      <td>-7.27e+01</td>\n",
       "      <td>-4.83e+01</td>\n",
       "      <td>-5.68e+00</td>\n",
       "      <td>-1.14e+02</td>\n",
       "      <td>-2.62e+01</td>\n",
       "      <td>-4.36e+01</td>\n",
       "      <td>-7.32e+01</td>\n",
       "      <td>-1.34e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.48e+01</td>\n",
       "      <td>-1.09e+01</td>\n",
       "      <td>-4.48e+01</td>\n",
       "      <td>-2.84e+00</td>\n",
       "      <td>-1.03e+01</td>\n",
       "      <td>-2.60e+00</td>\n",
       "      <td>-2.26e+01</td>\n",
       "      <td>-1.54e+01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.50</td>\n",
       "      <td>-9.20e-01</td>\n",
       "      <td>-5.99e-01</td>\n",
       "      <td>-8.90e-01</td>\n",
       "      <td>-8.49e-01</td>\n",
       "      <td>-6.92e-01</td>\n",
       "      <td>-7.68e-01</td>\n",
       "      <td>-5.54e-01</td>\n",
       "      <td>-2.09e-01</td>\n",
       "      <td>-6.43e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.28e-01</td>\n",
       "      <td>-5.42e-01</td>\n",
       "      <td>-1.62e-01</td>\n",
       "      <td>-3.55e-01</td>\n",
       "      <td>-3.17e-01</td>\n",
       "      <td>-3.27e-01</td>\n",
       "      <td>-7.08e-02</td>\n",
       "      <td>-5.30e-02</td>\n",
       "      <td>5.60</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.00</td>\n",
       "      <td>1.81e-02</td>\n",
       "      <td>6.55e-02</td>\n",
       "      <td>1.80e-01</td>\n",
       "      <td>-1.98e-02</td>\n",
       "      <td>-5.43e-02</td>\n",
       "      <td>-2.74e-01</td>\n",
       "      <td>4.01e-02</td>\n",
       "      <td>2.24e-02</td>\n",
       "      <td>-5.14e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.95e-02</td>\n",
       "      <td>6.78e-03</td>\n",
       "      <td>-1.12e-02</td>\n",
       "      <td>4.10e-02</td>\n",
       "      <td>1.66e-02</td>\n",
       "      <td>-5.21e-02</td>\n",
       "      <td>1.34e-03</td>\n",
       "      <td>1.12e-02</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.50</td>\n",
       "      <td>1.32e+00</td>\n",
       "      <td>8.04e-01</td>\n",
       "      <td>1.03e+00</td>\n",
       "      <td>7.43e-01</td>\n",
       "      <td>6.12e-01</td>\n",
       "      <td>3.99e-01</td>\n",
       "      <td>5.70e-01</td>\n",
       "      <td>3.27e-01</td>\n",
       "      <td>5.97e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.86e-01</td>\n",
       "      <td>5.29e-01</td>\n",
       "      <td>1.48e-01</td>\n",
       "      <td>4.40e-01</td>\n",
       "      <td>3.51e-01</td>\n",
       "      <td>2.41e-01</td>\n",
       "      <td>9.10e-02</td>\n",
       "      <td>7.83e-02</td>\n",
       "      <td>77.16</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.00</td>\n",
       "      <td>2.45e+00</td>\n",
       "      <td>2.21e+01</td>\n",
       "      <td>9.38e+00</td>\n",
       "      <td>1.69e+01</td>\n",
       "      <td>3.48e+01</td>\n",
       "      <td>7.33e+01</td>\n",
       "      <td>1.21e+02</td>\n",
       "      <td>2.00e+01</td>\n",
       "      <td>1.56e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.72e+01</td>\n",
       "      <td>1.05e+01</td>\n",
       "      <td>2.25e+01</td>\n",
       "      <td>4.58e+00</td>\n",
       "      <td>7.52e+00</td>\n",
       "      <td>3.52e+00</td>\n",
       "      <td>3.16e+01</td>\n",
       "      <td>3.38e+01</td>\n",
       "      <td>25691.16</td>\n",
       "      <td>1.00e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "count  284807.00  2.85e+05  2.85e+05  2.85e+05  2.85e+05  2.85e+05  2.85e+05   \n",
       "mean    94813.86  3.92e-15  5.68e-16 -8.76e-15  2.81e-15 -1.55e-15  2.04e-15   \n",
       "std     47488.15  1.96e+00  1.65e+00  1.52e+00  1.42e+00  1.38e+00  1.33e+00   \n",
       "min         0.00 -5.64e+01 -7.27e+01 -4.83e+01 -5.68e+00 -1.14e+02 -2.62e+01   \n",
       "25%     54201.50 -9.20e-01 -5.99e-01 -8.90e-01 -8.49e-01 -6.92e-01 -7.68e-01   \n",
       "50%     84692.00  1.81e-02  6.55e-02  1.80e-01 -1.98e-02 -5.43e-02 -2.74e-01   \n",
       "75%    139320.50  1.32e+00  8.04e-01  1.03e+00  7.43e-01  6.12e-01  3.99e-01   \n",
       "max    172792.00  2.45e+00  2.21e+01  9.38e+00  1.69e+01  3.48e+01  7.33e+01   \n",
       "\n",
       "             V7        V8        V9  ...       V21       V22       V23  \\\n",
       "count  2.85e+05  2.85e+05  2.85e+05  ...  2.85e+05  2.85e+05  2.85e+05   \n",
       "mean  -1.70e-15 -1.89e-16 -3.15e-15  ...  1.47e-16  8.04e-16  5.28e-16   \n",
       "std    1.24e+00  1.19e+00  1.10e+00  ...  7.35e-01  7.26e-01  6.24e-01   \n",
       "min   -4.36e+01 -7.32e+01 -1.34e+01  ... -3.48e+01 -1.09e+01 -4.48e+01   \n",
       "25%   -5.54e-01 -2.09e-01 -6.43e-01  ... -2.28e-01 -5.42e-01 -1.62e-01   \n",
       "50%    4.01e-02  2.24e-02 -5.14e-02  ... -2.95e-02  6.78e-03 -1.12e-02   \n",
       "75%    5.70e-01  3.27e-01  5.97e-01  ...  1.86e-01  5.29e-01  1.48e-01   \n",
       "max    1.21e+02  2.00e+01  1.56e+01  ...  2.72e+01  1.05e+01  2.25e+01   \n",
       "\n",
       "            V24       V25       V26       V27       V28     Amount     Class  \n",
       "count  2.85e+05  2.85e+05  2.85e+05  2.85e+05  2.85e+05  284807.00  2.85e+05  \n",
       "mean   4.46e-15  1.43e-15  1.70e-15 -3.66e-16 -1.22e-16      88.35  1.73e-03  \n",
       "std    6.06e-01  5.21e-01  4.82e-01  4.04e-01  3.30e-01     250.12  4.15e-02  \n",
       "min   -2.84e+00 -1.03e+01 -2.60e+00 -2.26e+01 -1.54e+01       0.00  0.00e+00  \n",
       "25%   -3.55e-01 -3.17e-01 -3.27e-01 -7.08e-02 -5.30e-02       5.60  0.00e+00  \n",
       "50%    4.10e-02  1.66e-02 -5.21e-02  1.34e-03  1.12e-02      22.00  0.00e+00  \n",
       "75%    4.40e-01  3.51e-01  2.41e-01  9.10e-02  7.83e-02      77.16  0.00e+00  \n",
       "max    4.58e+00  7.52e+00  3.52e+00  3.16e+01  3.38e+01   25691.16  1.00e+00  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('precision',2)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking transaction distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:36:55.511558Z",
     "iopub.status.busy": "2021-11-27T02:36:55.511231Z",
     "iopub.status.idle": "2021-11-27T02:36:55.556066Z",
     "shell.execute_reply": "2021-11-27T02:36:55.555187Z",
     "shell.execute_reply.started": "2021-11-27T02:36:55.511525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Transaction are: 284807\n",
      "Total number of Secured Transaction are: 284315\n",
      "Total number of Fraud Transaction are: 492\n",
      "Percentage of Fraud Transaction are: 0.17\n"
     ]
    }
   ],
   "source": [
    "Total_transactions = len(data)\n",
    "secured = len(data[data.Class == 0])\n",
    "fraud = len(data[data.Class == 1])\n",
    "fraud_percentage = round(fraud/secured*100, 2)\n",
    "print('Total number of Transaction are:', Total_transactions)\n",
    "print('Total number of Secured Transaction are:', secured)\n",
    "print('Total number of Fraud Transaction are:', fraud)\n",
    "print('Percentage of Fraud Transaction are:', fraud_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Independent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:45:13.002192Z",
     "iopub.status.busy": "2021-11-27T02:45:13.001828Z",
     "iopub.status.idle": "2021-11-27T02:45:13.068573Z",
     "shell.execute_reply": "2021-11-27T02:45:13.067940Z",
     "shell.execute_reply.started": "2021-11-27T02:45:13.002161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>2.54</td>\n",
       "      <td>1.38</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.83e-02</td>\n",
       "      <td>2.78e-01</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>1.34e-01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-2.26e-01</td>\n",
       "      <td>-6.39e-01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-8.98e-03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>...</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.48e-01</td>\n",
       "      <td>7.72e-01</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-5.54e-02</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>1.79</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-1.08e-01</td>\n",
       "      <td>5.27e-03</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>6.27e-02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-9.43e-03</td>\n",
       "      <td>7.98e-01</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.19e-01</td>\n",
       "      <td>0.22</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time    V1    V2    V3    V4    V5    V6    V7    V8    V9  ...   V20  \\\n",
       "0   0.0 -1.36 -0.07  2.54  1.38 -0.34  0.46  0.24  0.10  0.36  ...  0.25   \n",
       "1   0.0  1.19  0.27  0.17  0.45  0.06 -0.08 -0.08  0.09 -0.26  ... -0.07   \n",
       "2   1.0 -1.36 -1.34  1.77  0.38 -0.50  1.80  0.79  0.25 -1.51  ...  0.52   \n",
       "3   1.0 -0.97 -0.19  1.79 -0.86 -0.01  1.25  0.24  0.38 -1.39  ... -0.21   \n",
       "4   2.0 -1.16  0.88  1.55  0.40 -0.41  0.10  0.59 -0.27  0.82  ...  0.41   \n",
       "\n",
       "        V21       V22   V23   V24   V25   V26       V27   V28  Amount  \n",
       "0 -1.83e-02  2.78e-01 -0.11  0.07  0.13 -0.19  1.34e-01 -0.02  149.62  \n",
       "1 -2.26e-01 -6.39e-01  0.10 -0.34  0.17  0.13 -8.98e-03  0.01    2.69  \n",
       "2  2.48e-01  7.72e-01  0.91 -0.69 -0.33 -0.14 -5.54e-02 -0.06  378.66  \n",
       "3 -1.08e-01  5.27e-03 -0.19 -1.18  0.65 -0.22  6.27e-02  0.06  123.50  \n",
       "4 -9.43e-03  7.98e-01 -0.14  0.14 -0.21  0.50  2.19e-01  0.22   69.99  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.loc[:, data.columns != 'Class']\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize the data in X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:45:16.238954Z",
     "iopub.status.busy": "2021-11-27T02:45:16.238388Z",
     "iopub.status.idle": "2021-11-27T02:45:16.656695Z",
     "shell.execute_reply": "2021-11-27T02:45:16.655849Z",
     "shell.execute_reply.started": "2021-11-27T02:45:16.238914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.00</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.97</td>\n",
       "      <td>-2.45e-01</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>3.26e-01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>3.83e-01</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>3.31e-01</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.32</td>\n",
       "      <td>4.35e-02</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.96e-02</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-8.80e-01</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-2.23e-02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.00</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-3.65e-01</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>...</td>\n",
       "      <td>6.81e-01</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.06e+00</td>\n",
       "      <td>1.46</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-1.37e-01</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.00</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>1.18</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>-7.47e-03</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1.26</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.70e-01</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>7.27e-03</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>1.55e-01</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.00</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-2.95e-01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.74</td>\n",
       "      <td>...</td>\n",
       "      <td>5.30e-01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1.10e+00</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>1.04</td>\n",
       "      <td>5.44e-01</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>1.64</td>\n",
       "      <td>-6.07</td>\n",
       "      <td>6.10</td>\n",
       "      <td>-6.49</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>-3.89e+00</td>\n",
       "      <td>-1.96</td>\n",
       "      <td>-3.98</td>\n",
       "      <td>6.12</td>\n",
       "      <td>1.74</td>\n",
       "      <td>...</td>\n",
       "      <td>1.91e+00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.54e-01</td>\n",
       "      <td>1.62</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.34e+00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>-0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>1.64</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1.34</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>6.29e-01</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.53</td>\n",
       "      <td>...</td>\n",
       "      <td>7.73e-02</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.27e+00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>1.70e-01</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>1.64</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>1.91e+00</td>\n",
       "      <td>2.28</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>1.81e-03</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7.97e-01</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.51</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>1.10e-02</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>1.64</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-2.74e-01</td>\n",
       "      <td>0.47</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>1.65e-01</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.10e+00</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.70e-01</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>1.64</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-9.09e-03</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>1.27</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>4.97e-01</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.86e-01</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>-5.98e-03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3     4         5     6     7     8     9   ...  \\\n",
       "0      -2.00 -0.69 -0.04  1.67  0.97 -2.45e-01  0.35  0.19  0.08  0.33  ...   \n",
       "1      -2.00  0.61  0.16  0.11  0.32  4.35e-02 -0.06 -0.06  0.07 -0.23  ...   \n",
       "2      -2.00 -0.69 -0.81  1.17  0.27 -3.65e-01  1.35  0.64  0.21 -1.38  ...   \n",
       "3      -2.00 -0.49 -0.11  1.18 -0.61 -7.47e-03  0.94  0.19  0.32 -1.26  ...   \n",
       "4      -2.00 -0.59  0.53  1.02  0.28 -2.95e-01  0.07  0.48 -0.23  0.74  ...   \n",
       "...      ...   ...   ...   ...   ...       ...   ...   ...   ...   ...  ...   \n",
       "284802  1.64 -6.07  6.10 -6.49 -1.46 -3.89e+00 -1.96 -3.98  6.12  1.74  ...   \n",
       "284803  1.64 -0.37 -0.03  1.34 -0.52  6.29e-01  0.79  0.02  0.25  0.53  ...   \n",
       "284804  1.64  0.98 -0.18 -2.14 -0.39  1.91e+00  2.28 -0.24  0.59  0.39  ...   \n",
       "284805  1.64 -0.12  0.32  0.46  0.49 -2.74e-01  0.47 -0.55  0.57  0.36  ...   \n",
       "284806  1.64 -0.27 -0.11  0.46 -0.36 -9.09e-03 -0.49  1.27 -0.35  0.44  ...   \n",
       "\n",
       "              20    21        22    23    24    25    26        27    28    29  \n",
       "0       3.26e-01 -0.02  3.83e-01 -0.18  0.11  0.25 -0.39  3.31e-01 -0.06  0.24  \n",
       "1      -8.96e-02 -0.31 -8.80e-01  0.16 -0.56  0.32  0.26 -2.23e-02  0.04 -0.34  \n",
       "2       6.81e-01  0.34  1.06e+00  1.46 -1.14 -0.63 -0.29 -1.37e-01 -0.18  1.16  \n",
       "3      -2.70e-01 -0.15  7.27e-03 -0.30 -1.94  1.24 -0.46  1.55e-01  0.19  0.14  \n",
       "4       5.30e-01 -0.01  1.10e+00 -0.22  0.23 -0.40  1.04  5.44e-01  0.65 -0.07  \n",
       "...          ...   ...       ...   ...   ...   ...   ...       ...   ...   ...  \n",
       "284802  1.91e+00  0.29  1.54e-01  1.62 -0.84  2.76  0.52  2.34e+00  2.50 -0.35  \n",
       "284803  7.73e-02  0.29  1.27e+00  0.02 -1.68 -1.16 -0.82  1.70e-01 -0.16 -0.25  \n",
       "284804  1.81e-03  0.32  7.97e-01 -0.06  1.06  0.51 -0.18  1.10e-02 -0.08 -0.08  \n",
       "284805  1.65e-01  0.36  1.10e+00 -0.26  0.20 -1.09  1.13  2.70e-01  0.32 -0.31  \n",
       "284806  4.97e-01  0.36  8.86e-01  0.60  0.01 -0.91 -1.70 -5.98e-03  0.04  0.51  \n",
       "\n",
       "[284807 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaled = preprocessing.scale(X)\n",
    "X = pd.DataFrame(x_scaled)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:45:20.661675Z",
     "iopub.status.busy": "2021-11-27T02:45:20.661168Z",
     "iopub.status.idle": "2021-11-27T02:45:20.667328Z",
     "shell.execute_reply": "2021-11-27T02:45:20.666537Z",
     "shell.execute_reply.started": "2021-11-27T02:45:20.661624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data[\"Class\"].to_numpy()\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:45:23.698343Z",
     "iopub.status.busy": "2021-11-27T02:45:23.698047Z",
     "iopub.status.idle": "2021-11-27T02:45:23.903687Z",
     "shell.execute_reply": "2021-11-27T02:45:23.902847Z",
     "shell.execute_reply.started": "2021-11-27T02:45:23.698311Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.99658302, -0.69424232, -0.04407492,  1.6727735 ,  0.97336551,\n",
       "        -0.24511658,  0.34706795,  0.19367894,  0.08263728,  0.33112778,\n",
       "         0.08338555, -0.54040704, -0.61829572, -0.99609892, -0.32461019,\n",
       "         1.60401384, -0.53683287,  0.24486345,  0.03076993,  0.49628203,\n",
       "         0.32611802, -0.02492336,  0.38285444, -0.17691133,  0.11050692,\n",
       "         0.24658544, -0.39217043,  0.33089162, -0.06378115,  0.24496426],\n",
       "       [-1.99658302,  0.60849633,  0.16117592,  0.1097971 ,  0.31652293,\n",
       "         0.04348335, -0.06181997, -0.06370021,  0.07125348, -0.23249419,\n",
       "        -0.15334963,  1.58000285,  1.06608857,  0.4914182 , -0.14998248,\n",
       "         0.69436042,  0.52943375, -0.13516997, -0.21876258, -0.17908605,\n",
       "        -0.08961086, -0.3073768 , -0.88007675,  0.16220118, -0.56113055,\n",
       "         0.3206939 ,  0.26106948, -0.02225568,  0.04460752, -0.34247454],\n",
       "       [-1.99656197, -0.69350046, -0.81157783,  1.16946849,  0.26823129,\n",
       "        -0.36457179,  1.35145359,  0.63977564,  0.20737273, -1.37867535,\n",
       "         0.19069961,  0.61182971,  0.06613662,  0.72069985, -0.17311389,\n",
       "         2.56290618, -3.29823537,  1.30686788, -0.14478999, -2.77856085,\n",
       "         0.68097497,  0.3376317 ,  1.06335827,  1.45631975, -1.13809214,\n",
       "        -0.62853672, -0.28844675, -0.13713686, -0.18102083,  1.16068593],\n",
       "       [-1.99656197, -0.4933249 , -0.11216942,  1.18251645, -0.60972664,\n",
       "        -0.00746888,  0.93614983,  0.19207064,  0.3160176 , -1.26250317,\n",
       "        -0.05046795, -0.22189161,  0.17837099,  0.5101687 , -0.30036049,\n",
       "        -0.68983741, -1.20929599, -0.80544464,  2.34530452, -1.51420492,\n",
       "        -0.26985523, -0.1474433 ,  0.00726691, -0.30477655, -1.94102714,\n",
       "         1.24190371, -0.46021734,  0.15539621,  0.18618859,  0.14053425],\n",
       "       [-1.99654091, -0.59132976,  0.53154105,  1.02141168,  0.2846554 ,\n",
       "        -0.29501544,  0.07199858,  0.47930228, -0.22651023,  0.74432629,\n",
       "         0.69162503, -0.80614659,  0.53862665,  1.35224435, -1.16803351,\n",
       "         0.19132347, -0.51520512, -0.27908079, -0.045569  ,  0.9870373 ,\n",
       "         0.52993879, -0.01283922,  1.10001127, -0.2201234 ,  0.23325009,\n",
       "        -0.39520164,  1.0416113 ,  0.5436198 ,  0.65181592, -0.07340334]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting Data into Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:45:28.234209Z",
     "iopub.status.busy": "2021-11-27T02:45:28.233901Z",
     "iopub.status.idle": "2021-11-27T02:45:28.391375Z",
     "shell.execute_reply": "2021-11-27T02:45:28.390485Z",
     "shell.execute_reply.started": "2021-11-27T02:45:28.234174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (227845, 30) (227845,)\n",
      "Test set: (56962, 30) (56962,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=2)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C** parameter indicates **inverse of regularization strength** which must be a positive float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:45:33.238340Z",
     "iopub.status.busy": "2021-11-27T02:45:33.237652Z",
     "iopub.status.idle": "2021-11-27T02:45:35.268544Z",
     "shell.execute_reply": "2021-11-27T02:45:35.267654Z",
     "shell.execute_reply.started": "2021-11-27T02:45:33.238291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, solver='liblinear')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
    "LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can predict using our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:45:42.357848Z",
     "iopub.status.busy": "2021-11-27T02:45:42.357431Z",
     "iopub.status.idle": "2021-11-27T02:45:42.370958Z",
     "shell.execute_reply": "2021-11-27T02:45:42.369659Z",
     "shell.execute_reply.started": "2021-11-27T02:45:42.357818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = LR.predict(X_test)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**predict_proba**  returns estimates for all classes, ordered by the label of classes. So, the first column is the probability of class 0, P(Y=0|X), and second column is probability of class 1, P(Y=1|X):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:45:45.873997Z",
     "iopub.status.busy": "2021-11-27T02:45:45.873426Z",
     "iopub.status.idle": "2021-11-27T02:45:45.887105Z",
     "shell.execute_reply": "2021-11-27T02:45:45.886242Z",
     "shell.execute_reply.started": "2021-11-27T02:45:45.873961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99687968, 0.00312032],\n",
       "       [0.99682549, 0.00317451],\n",
       "       [0.99760094, 0.00239906],\n",
       "       ...,\n",
       "       [0.99740355, 0.00259645],\n",
       "       [0.99480663, 0.00519337],\n",
       "       [0.98910047, 0.01089953]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_prob = LR.predict_proba(X_test)\n",
    "yhat_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Evaluation by Jaccard Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can define jaccard as the size of the intersection divided by the size of the union of the two label sets. If the entire set of predicted labels for a sample strictly matches with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:45:49.426607Z",
     "iopub.status.busy": "2021-11-27T02:45:49.426282Z",
     "iopub.status.idle": "2021-11-27T02:45:49.446622Z",
     "shell.execute_reply": "2021-11-27T02:45:49.445788Z",
     "shell.execute_reply.started": "2021-11-27T02:45:49.426575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.93"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_AS = round(jaccard_score(y_test, yhat,pos_label=0)*100,2)\n",
    "\n",
    "LR_AS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Evaluation by Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of looking at the accuracy of the classifier is to look at **confusion matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:45:53.504418Z",
     "iopub.status.busy": "2021-11-27T02:45:53.504140Z",
     "iopub.status.idle": "2021-11-27T02:45:53.779447Z",
     "shell.execute_reply": "2021-11-27T02:45:53.778859Z",
     "shell.execute_reply.started": "2021-11-27T02:45:53.504388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[   53    31]\n",
      " [    8 56870]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#yhat=logreg_cv.predict(X_test)\n",
    "cm = confusion_matrix(y_test, yhat, labels=[1,0])\n",
    "print('Confusion matrix:''\\n', cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this confusion matrix, the first row presents the negetive and second row presents the positive result. So we have a total of 56870 true positive and 8 false positive result. That explains, out of 56870+8= 56878, we have 56870 successfully classified normal transaction and 8 were falsely classified as normal but they were fraudlent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:46:02.128443Z",
     "iopub.status.busy": "2021-11-27T02:46:02.127743Z",
     "iopub.status.idle": "2021-11-27T02:46:02.193467Z",
     "shell.execute_reply": "2021-11-27T02:46:02.192465Z",
     "shell.execute_reply.started": "2021-11-27T02:46:02.128400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56878\n",
      "           1       0.87      0.63      0.73        84\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.93      0.82      0.87     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the count of each section, we can calculate precision and recall of each label:\n",
    "\n",
    "*   **Precision** is a measure of the accuracy provided that a class label has been predicted. It is defined by: precision = TP / (TP + FP)\n",
    "\n",
    "*   **Recall** is the true positive rate. It is defined as: Recall =  TP / (TP + FN)\n",
    "\n",
    "So, we can calculate the precision and recall of each class.\n",
    "\n",
    "**F1 score:**\n",
    "Now we are in the position to calculate the F1 scores for each label based on the precision and recall of that label.\n",
    "\n",
    "The F1 score is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0. It is a good way to show that a classifer has a good value for both recall and precision.\n",
    "\n",
    "Finally, we can tell the average accuracy for this classifier is the average of the F1-score for both labels, which is 1.0 in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees with Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first create an instance of the **DecisionTreeClassifier** called **fraudTree**.\n",
    "    Inside of the classifier, specify  *criterion=\"entropy\"* so we can see the information gain of each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:46:07.025490Z",
     "iopub.status.busy": "2021-11-27T02:46:07.024883Z",
     "iopub.status.idle": "2021-11-27T02:46:07.031741Z",
     "shell.execute_reply": "2021-11-27T02:46:07.031120Z",
     "shell.execute_reply.started": "2021-11-27T02:46:07.025444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraudTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n",
    "fraudTree # it shows the default parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will fit the data with the training feature matrix <b> X_trainset </b> and training  response vector <b> y_trainset </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:46:10.686940Z",
     "iopub.status.busy": "2021-11-27T02:46:10.685923Z",
     "iopub.status.idle": "2021-11-27T02:46:18.671065Z",
     "shell.execute_reply": "2021-11-27T02:46:18.670011Z",
     "shell.execute_reply.started": "2021-11-27T02:46:10.686892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraudTree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some <b>predictions</b> on the testing dataset and store it into a variable called <b>predTree</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:46:29.217119Z",
     "iopub.status.busy": "2021-11-27T02:46:29.216792Z",
     "iopub.status.idle": "2021-11-27T02:46:29.226429Z",
     "shell.execute_reply": "2021-11-27T02:46:29.225605Z",
     "shell.execute_reply.started": "2021-11-27T02:46:29.217085Z"
    }
   },
   "outputs": [],
   "source": [
    "predTree = fraudTree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print out <b>predTree</b> and <b>y_test</b> if you want to visually compare the predictions to the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:46:35.874079Z",
     "iopub.status.busy": "2021-11-27T02:46:35.872984Z",
     "iopub.status.idle": "2021-11-27T02:46:35.880093Z",
     "shell.execute_reply": "2021-11-27T02:46:35.879143Z",
     "shell.execute_reply.started": "2021-11-27T02:46:35.874035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print (predTree [0:5])\n",
    "print (y_test [0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Evaluation by Jaccard Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define jaccard as the size of the intersection divided by the size of the union of the two label sets. If the entire set of predicted labels for a sample strictly matches with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:46:41.382957Z",
     "iopub.status.busy": "2021-11-27T02:46:41.381790Z",
     "iopub.status.idle": "2021-11-27T02:46:41.405611Z",
     "shell.execute_reply": "2021-11-27T02:46:41.405032Z",
     "shell.execute_reply.started": "2021-11-27T02:46:41.382896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.95"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_AS = round(jaccard_score(y_test, predTree,pos_label=0)*100,2)\n",
    "\n",
    "DT_AS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Evaluation by Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of looking at the accuracy of the classifier is to look at **confusion matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:46:45.769408Z",
     "iopub.status.busy": "2021-11-27T02:46:45.768888Z",
     "iopub.status.idle": "2021-11-27T02:46:46.016574Z",
     "shell.execute_reply": "2021-11-27T02:46:46.015646Z",
     "shell.execute_reply.started": "2021-11-27T02:46:45.769369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[   66    18]\n",
      " [   11 56867]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, predTree, labels=[1,0])\n",
    "print('Confusion matrix:''\\n', cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this confusion matrix, the first row presents the negetive and second row presents the positive result. So we have a total of 56867 true positive and 11 false positive result. That explains, out of 56867+11= 56878, we have 56867 successfully classified normal transaction and 11 were falsely classified as normal but they were fraudlent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:46:50.307218Z",
     "iopub.status.busy": "2021-11-27T02:46:50.306870Z",
     "iopub.status.idle": "2021-11-27T02:46:50.375623Z",
     "shell.execute_reply": "2021-11-27T02:46:50.374530Z",
     "shell.execute_reply.started": "2021-11-27T02:46:50.307181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56878\n",
      "           1       0.86      0.79      0.82        84\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.93      0.89      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, predTree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the count of each section, we can calculate precision and recall of each label:\n",
    "\n",
    "*   **Precision** is a measure of the accuracy provided that a class label has been predicted. It is defined by: precision = TP / (TP + FP)\n",
    "\n",
    "*   **Recall** is the true positive rate. It is defined as: Recall =  TP / (TP + FN)\n",
    "\n",
    "So, we can calculate the precision and recall of each class.\n",
    "\n",
    "**F1 score:**\n",
    "Now we are in the position to calculate the F1 scores for each label based on the precision and recall of that label.\n",
    "\n",
    "The F1 score is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0. It is a good way to show that a classifer has a good value for both recall and precision.\n",
    "\n",
    "Finally, we can tell the average accuracy for this classifier is the average of the F1-score for both labels, which is 1.0 in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest-neighbours with Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start the training algorithm with k=4 for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:46:55.014206Z",
     "iopub.status.busy": "2021-11-27T02:46:55.013933Z",
     "iopub.status.idle": "2021-11-27T02:46:56.843988Z",
     "shell.execute_reply": "2021-11-27T02:46:56.843117Z",
     "shell.execute_reply.started": "2021-11-27T02:46:55.014177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 4\n",
    "#Train Model and Predict  \n",
    "neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n",
    "neigh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the model to make predictions on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:46:58.006685Z",
     "iopub.status.busy": "2021-11-27T02:46:58.006011Z",
     "iopub.status.idle": "2021-11-27T02:56:07.327364Z",
     "shell.execute_reply": "2021-11-27T02:56:07.326313Z",
     "shell.execute_reply.started": "2021-11-27T02:46:58.006642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = neigh.predict(X_test)\n",
    "yhat[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Evaluation by Jaccard Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define jaccard as the size of the intersection divided by the size of the union of the two label sets. If the entire set of predicted labels for a sample strictly matches with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:56:07.329493Z",
     "iopub.status.busy": "2021-11-27T02:56:07.329217Z",
     "iopub.status.idle": "2021-11-27T02:56:07.350920Z",
     "shell.execute_reply": "2021-11-27T02:56:07.350330Z",
     "shell.execute_reply.started": "2021-11-27T02:56:07.329462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.96"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_AS = round(jaccard_score(y_test, yhat,pos_label=0)*100,2)\n",
    "\n",
    "KNN_AS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Evaluation by Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of looking at the accuracy of the classifier is to look at **confusion matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T02:56:07.352620Z",
     "iopub.status.busy": "2021-11-27T02:56:07.351846Z",
     "iopub.status.idle": "2021-11-27T02:56:07.603030Z",
     "shell.execute_reply": "2021-11-27T02:56:07.602211Z",
     "shell.execute_reply.started": "2021-11-27T02:56:07.352570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[   67    17]\n",
      " [    3 56875]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, yhat, labels=[1,0])\n",
    "print('Confusion matrix:''\\n', cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this confusion matrix, the first row presents the negetive and second row presents the positive result. So we have a total of 56875 true positive and 3 false positive result. That explains, out of 56875+3= 56878, we have 56875 successfully classified normal transaction and 3 were falsely classified as normal but they were fraudlent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T03:09:30.570385Z",
     "iopub.status.busy": "2021-11-27T03:09:30.570068Z",
     "iopub.status.idle": "2021-11-27T03:09:30.635517Z",
     "shell.execute_reply": "2021-11-27T03:09:30.634403Z",
     "shell.execute_reply.started": "2021-11-27T03:09:30.570344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56878\n",
      "           1       0.96      0.80      0.87        84\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.98      0.90      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the count of each section, we can calculate precision and recall of each label:\n",
    "\n",
    "*   **Precision** is a measure of the accuracy provided that a class label has been predicted. It is defined by: precision = TP / (TP + FP)\n",
    "\n",
    "*   **Recall** is the true positive rate. It is defined as: Recall =  TP / (TP + FN)\n",
    "\n",
    "So, we can calculate the precision and recall of each class.\n",
    "\n",
    "**F1 score:**\n",
    "Now we are in the position to calculate the F1 scores for each label based on the precision and recall of that label.\n",
    "\n",
    "The F1 score is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0. It is a good way to show that a classifer has a good value for both recall and precision.\n",
    "\n",
    "Finally, we can tell the average accuracy for this classifier is the average of the F1-score for both labels, which is 1.0 in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine with Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with Radial Basis Function (RBF) kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T03:09:36.722202Z",
     "iopub.status.busy": "2021-11-27T03:09:36.721372Z",
     "iopub.status.idle": "2021-11-27T03:22:29.448416Z",
     "shell.execute_reply": "2021-11-27T03:22:29.447453Z",
     "shell.execute_reply.started": "2021-11-27T03:09:36.722152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After being fitted, the model can then be used to predict new values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T03:22:29.450887Z",
     "iopub.status.busy": "2021-11-27T03:22:29.450550Z",
     "iopub.status.idle": "2021-11-27T03:22:41.155156Z",
     "shell.execute_reply": "2021-11-27T03:22:41.154320Z",
     "shell.execute_reply.started": "2021-11-27T03:22:29.450844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = clf.predict(X_test)\n",
    "yhat [0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Evaluation by Jaccard Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define jaccard as the size of the intersection divided by the size of the union of the two label sets. If the entire set of predicted labels for a sample strictly matches with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T03:22:41.157231Z",
     "iopub.status.busy": "2021-11-27T03:22:41.156575Z",
     "iopub.status.idle": "2021-11-27T03:22:41.178111Z",
     "shell.execute_reply": "2021-11-27T03:22:41.177205Z",
     "shell.execute_reply.started": "2021-11-27T03:22:41.157198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.96"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_AS = round(jaccard_score(y_test, yhat,pos_label=0)*100,2)\n",
    "\n",
    "SVM_AS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Evaluation by Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of looking at the accuracy of the classifier is to look at **confusion matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T03:09:27.557313Z",
     "iopub.status.busy": "2021-11-27T03:09:27.556909Z",
     "iopub.status.idle": "2021-11-27T03:09:27.803071Z",
     "shell.execute_reply": "2021-11-27T03:09:27.802134Z",
     "shell.execute_reply.started": "2021-11-27T03:09:27.557269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[   64    20]\n",
      " [    4 56874]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, yhat, labels=[1,0])\n",
    "print('Confusion matrix:''\\n', cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this confusion matrix, the first row presents the negetive and second row presents the positive result. So we have a total of 56874 true positive and 4 false positive result. That explains, out of 56874+4= 56878, we have 56874 successfully classified normal transaction and 4 were falsely classified as normal but they were fraudlent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T03:22:41.179956Z",
     "iopub.status.busy": "2021-11-27T03:22:41.179736Z",
     "iopub.status.idle": "2021-11-27T03:22:41.246430Z",
     "shell.execute_reply": "2021-11-27T03:22:41.245721Z",
     "shell.execute_reply.started": "2021-11-27T03:22:41.179930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56878\n",
      "           1       0.94      0.76      0.84        84\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.88      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the count of each section, we can calculate precision and recall of each label:\n",
    "\n",
    "*   **Precision** is a measure of the accuracy provided that a class label has been predicted. It is defined by: precision = TP / (TP + FP)\n",
    "\n",
    "*   **Recall** is the true positive rate. It is defined as: Recall =  TP / (TP + FN)\n",
    "\n",
    "So, we can calculate the precision and recall of each class.\n",
    "\n",
    "**F1 score:**\n",
    "Now we are in the position to calculate the F1 scores for each label based on the precision and recall of that label.\n",
    "\n",
    "The F1 score is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0. It is a good way to show that a classifer has a good value for both recall and precision.\n",
    "\n",
    "Finally, we can tell the average accuracy for this classifier is the average of the F1-score for both labels, which is 1.0 in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T03:29:08.474568Z",
     "iopub.status.busy": "2021-11-27T03:29:08.474206Z",
     "iopub.status.idle": "2021-11-27T03:33:45.921451Z",
     "shell.execute_reply": "2021-11-27T03:33:45.920509Z",
     "shell.execute_reply.started": "2021-11-27T03:29:08.474532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier()\n",
    "\n",
    "#Train the model using Training Dataset\n",
    "RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After being fitted, the model can then be used to predict new values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T03:33:45.923222Z",
     "iopub.status.busy": "2021-11-27T03:33:45.922946Z",
     "iopub.status.idle": "2021-11-27T03:33:46.541795Z",
     "shell.execute_reply": "2021-11-27T03:33:46.541106Z",
     "shell.execute_reply.started": "2021-11-27T03:33:45.923192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = RF.predict(X_test)\n",
    "yhat [0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Evaluation by Jaccard Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define jaccard as the size of the intersection divided by the size of the union of the two label sets. If the entire set of predicted labels for a sample strictly matches with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T03:33:46.543241Z",
     "iopub.status.busy": "2021-11-27T03:33:46.542863Z",
     "iopub.status.idle": "2021-11-27T03:33:46.564156Z",
     "shell.execute_reply": "2021-11-27T03:33:46.563281Z",
     "shell.execute_reply.started": "2021-11-27T03:33:46.543210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.96"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_AS = round(jaccard_score(y_test, yhat,pos_label=0)*100,2)\n",
    "RF_AS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Evaluation by Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of looking at the accuracy of the classifier is to look at **confusion matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T03:33:46.566084Z",
     "iopub.status.busy": "2021-11-27T03:33:46.565780Z",
     "iopub.status.idle": "2021-11-27T03:33:46.810840Z",
     "shell.execute_reply": "2021-11-27T03:33:46.809914Z",
     "shell.execute_reply.started": "2021-11-27T03:33:46.566052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[   69    15]\n",
      " [    5 56873]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, yhat, labels=[1,0])\n",
    "print('Confusion matrix:''\\n', cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this confusion matrix, the first row presents the negetive and second row presents the positive result. So we have a total of 56873 true positive and 5 false positive result. That explains, out of 56873+5= 56878, we have 56873 successfully classified normal transaction and 5 were falsely classified as normal but they were fraudlent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T03:33:46.812357Z",
     "iopub.status.busy": "2021-11-27T03:33:46.811986Z",
     "iopub.status.idle": "2021-11-27T03:33:46.878175Z",
     "shell.execute_reply": "2021-11-27T03:33:46.877540Z",
     "shell.execute_reply.started": "2021-11-27T03:33:46.812310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56878\n",
      "           1       0.93      0.82      0.87        84\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.91      0.94     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the count of each section, we can calculate precision and recall of each label:\n",
    "\n",
    "*   **Precision** is a measure of the accuracy provided that a class label has been predicted. It is defined by: precision = TP / (TP + FP)\n",
    "\n",
    "*   **Recall** is the true positive rate. It is defined as: Recall =  TP / (TP + FN)\n",
    "\n",
    "So, we can calculate the precision and recall of each class.\n",
    "\n",
    "**F1 score:**\n",
    "Now we are in the position to calculate the F1 scores for each label based on the precision and recall of that label.\n",
    "\n",
    "The F1 score is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0. It is a good way to show that a classifer has a good value for both recall and precision.\n",
    "\n",
    "Finally, we can tell the average accuracy for this classifier is the average of the F1-score for both labels, which is 1.0 in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Performed Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T03:34:28.860496Z",
     "iopub.status.busy": "2021-11-27T03:34:28.860026Z",
     "iopub.status.idle": "2021-11-27T03:34:28.873834Z",
     "shell.execute_reply": "2021-11-27T03:34:28.873204Z",
     "shell.execute_reply.started": "2021-11-27T03:34:28.860463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Accuracy_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-Nearest-neighbours (KNN)</td>\n",
       "      <td>99.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machine (SVM)</td>\n",
       "      <td>99.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>99.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Trees</td>\n",
       "      <td>99.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>99.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Models  Accuracy_Score\n",
       "2    K-Nearest-neighbours (KNN)           99.96\n",
       "3  Support Vector Machine (SVM)           99.96\n",
       "4                 Random Forest           99.96\n",
       "1                Decision Trees           99.95\n",
       "0           Logistic Regression           99.93"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BPM = pd.DataFrame({\n",
    "    'Models': ['Logistic Regression', 'Decision Trees','K-Nearest-neighbours (KNN)', \n",
    "               'Support Vector Machine (SVM)', 'Random Forest'],\n",
    "    'Accuracy_Score': [LR_AS, DT_AS, KNN_AS, SVM_AS, RF_AS]})\n",
    "\n",
    "BPM.sort_values(by='Accuracy_Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   We found **0.17%** Fraud Transaction were occured.\n",
    "*   We found **99.96%** accuracy score for **Random Forest**. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you very much for reading this NoteBook. Please share your comments and suggestions for improving more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
